{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "/Users/lyw/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import gradio as gr\n",
    "import openai as OpenAI\n",
    "from langchain_upstage import ChatUpstage\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "from langchain_core.messages import HumanMessage, SystemMessage \n",
    "from langchain.schema import Document\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import MultiQueryRetriever\n",
    "from langchain.retrievers import BM25Retriever\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Predibase\n",
    "from langchain.schema import Document\n",
    "from typing import TypedDict\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_upstage import UpstageGroundednessCheck\n",
    "from predibase import Predibase as pb\n",
    "from kiwipiepy import Kiwi\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from googleapiclient.discovery import build\n",
    "import requests\n",
    "\n",
    "# langchain smith API KEY\n",
    "LANGCHAIN_API_KEY=\"...\"\n",
    "LANGCHAIN_TRACING_V2='true'\n",
    "LANGCHAIN_ENDPOINT=\"https://api.smith.langchain.com\"\n",
    "LANGCHAIN_PROJECT=\"bisAI\"\n",
    "\n",
    "# Chat model API KEY\n",
    "OPENAI_API_KEY = '...'\n",
    "UPSTAGE_API_KEY = '...'\n",
    "PREDIBASE_API_KEY = '...'\n",
    "\n",
    "# Google Custom Search API KEY, ID\n",
    "CSE_API_KEY = '...'\n",
    "CSE_ID = '...'\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = LANGCHAIN_TRACING_V2\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = LANGCHAIN_ENDPOINT\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = LANGCHAIN_PROJECT\n",
    "\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = LANGCHAIN_API_KEY\n",
    "os.environ[\"UPSTAGE_API_KEY\"] = UPSTAGE_API_KEY\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "os.environ[\"PREDIBASE_API_KEY\"] = PREDIBASE_API_KEY\n",
    "\n",
    "kiwi = Kiwi()\n",
    "upstage_ground_checker = UpstageGroundednessCheck()\n",
    "OpenAIembedding = OpenAIEmbeddings()\n",
    "\n",
    "# Data CSV file directory\n",
    "sup_product_df = pd.read_csv(\"db/nutrient_data_final.csv\")\n",
    "med_product_df = pd.read_csv(\"db/new_medi.csv\")\n",
    "med_info_df = pd.read_csv(\"db/pdf_contents.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kiwi_tokenize(text):\n",
    "    return [token.form for token in kiwi.tokenize(text)]\n",
    "  \n",
    "def google_search(query, search_type='image', num_results=5):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=CSE_API_KEY)\n",
    "    res = service.cse().list(\n",
    "        q=query,\n",
    "        cx=CSE_ID,\n",
    "        searchType='image' if search_type == 'image' else None,  # 이미지 검색 여부\n",
    "        num=num_results\n",
    "    ).execute()\n",
    "    return res['items']\n",
    "\n",
    "def url_image_to_text(image_url):\n",
    "  api_key = UPSTAGE_API_KEY  # UPSTAGE Document OCR API KEY\n",
    "  image_url = image_url\n",
    "  url = api_key\n",
    "  headers = {\"Authorization\": f\"Bearer {api_key}\"}\n",
    "\n",
    "  # Image Download\n",
    "  image_response = requests.get(image_url)\n",
    "  files = {\"document\": (\"image.png\", image_response.content, \"image/png\")}\n",
    "\n",
    "  response = requests.post(url, headers=headers, files=files)\n",
    "  return response.json()[\"text\"]\n",
    "\n",
    "def find_info_by_web_search(query):\n",
    "  #query google image search\n",
    "  query_image = google_search(query)\n",
    "  additional_query_info = \"\"\n",
    "  #Image to Text \n",
    "  for i in range(5):\n",
    "    try:\n",
    "      additional_query_info = url_image_to_text(query_image[i]['link'])\n",
    "      break\n",
    "    except:\n",
    "      print('fail')\n",
    "      continue\n",
    "  return additional_query_info\n",
    "\n",
    "def combine_sup_product(row):\n",
    "    # 각 컬럼의 내용을 결합하여 하나의 텍스트로 만듦\n",
    "    return f\"제품명: {row['이름']}\\n영양성분: {row['성분']}\\n기능: {row['기능']}\\n주의사항: {row['주의사항']}\"\n",
    "def combine_pdf(row):\n",
    "    return f\"제목: {row['제목']}\\n요약: {row['요약']}\\n내용: {row['내용']}\"\n",
    "def combine_med_product(row):\n",
    "    return f\"제품명: {row['제품명']}\\n주성분: {row['주성분']}\\n기능: {row['이 약의 효능은 무엇입니까?']}\\n주의사항: {row['이 약의 사용상 주의사항은 무엇입니까?']}\"\n",
    "\n",
    "def retriever_medi(documents, embedding_model):\n",
    "    vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "    faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\": 1})\n",
    "    kiwi_bm25_retriever = BM25Retriever.from_documents(documents, preprocess_func=kiwi_tokenize)\n",
    "    \n",
    "    kiwibm25_faiss_73 = EnsembleRetriever(\n",
    "    retrievers=[kiwi_bm25_retriever, faiss_retriever],  # 사용할 검색 모델의 리스트\n",
    "    weights=[0.7, 0.3],  # 각 검색 모델의 결과에 적용할 가중치\n",
    "    search_type=\"mmr\",  # 검색 결과의 다양성을 증진시키는 MMR 방식을 사용\n",
    "    )\n",
    "    return faiss_retriever\n",
    "\n",
    "def retriever_sup(documents, embedding_model):\n",
    "    vector_store = FAISS.from_documents(documents, embedding_model)\n",
    "    faiss_retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "    kiwi_bm25_retriever = BM25Retriever.from_documents(documents, preprocess_func=kiwi_tokenize)\n",
    "    \n",
    "    kiwibm25_faiss_73 = EnsembleRetriever(\n",
    "    retrievers=[kiwi_bm25_retriever, faiss_retriever],\n",
    "    weights=[0.7, 0.3],\n",
    "    search_type=\"mmr\",\n",
    "    )\n",
    "    return kiwibm25_faiss_73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_sup_product = [Document(page_content=combine_sup_product(row), metadata={\"제품명\": row['이름']}) for _, row in sup_product_df.iterrows()]\n",
    "documents_medi_product = [Document(page_content=combine_med_product(row), metadata={\"제품명\": row['제품명']}) for _, row in med_product_df.iterrows()]\n",
    "documents_medi_info = [Document(page_content=combine_pdf(row), metadata={\"제목\": row['제목']}) for _, row in med_info_df.iterrows()]\n",
    "\n",
    "OpenAIembedding = OpenAIEmbeddings()\n",
    "SolarEmbedding = UpstageEmbeddings(api_key=UPSTAGE_API_KEY, model=\"solar-embedding-1-large\")\n",
    "\n",
    "embedding_model = OpenAIembedding\n",
    "#embedding_model = SolarEmbedding\n",
    "\n",
    "kiwibm25_faiss_73_sup_product = retriever_sup(documents_sup_product, embedding_model)\n",
    "kiwibm25_faiss_73_medi_product = retriever_medi(documents_medi_product, embedding_model)\n",
    "kiwibm25_faiss_73_medi_info = retriever_medi(documents_medi_info, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lyw/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'제품명': '루테인 지아잔틴 아스타잔틴'}, page_content='제품명: 루테인 지아잔틴 아스타잔틴\\n영양성분: 비타민A,210ug|아스타잔틴,6|루테인지아잔틴복합추출물,20|\\n기능: 시력 및 눈 피로감 케어|\\n주의사항: * 영, 유아, 어린이, 임산부 및 수유부는 섭취에 주의|* 과다섭취 시 일시적으로 피부가 황색으로 변할 수 있음|* β-카로틴의 흡수를 저해할 수 있음|* 임산부와 수유부, 질병치료 중인 분은 섭취 전 의사와 상담 후 섭취하십시오.|* 특정 성분에 알레르기가 있으신 분은 원료명을 확인 후 섭취하십시오.|* 개봉 또는 섭취 시 포장재에 의해 상처를 입을 수 있으니 주의하시기 바랍니다.|'),\n",
       " Document(metadata={'제품명': '비타앤 히알루론산 피치맛'}, page_content='제품명: 비타앤 히알루론산 피치맛\\n영양성분: 비타민C,300|히알루론산,120|\\n기능: 항산화|피부 건강|\\n주의사항: * 특이체질 및 알레르기 체질이신 경우 성분을 확인 하신 후 섭취하여 주시기 바랍니다.|* 포장지에 의해 상처를 입을수 있으니 주의 하시기 바랍니다.|* 유통기한이 경과한 제품은 섭취하지 마시기 바랍니다.|'),\n",
       " Document(metadata={'제품명': '루테인 지아잔틴 미니'}, page_content='제품명: 루테인 지아잔틴 미니\\n영양성분: 루테인,18.182|지아잔틴,1.818|\\n기능: 시력 및 눈 피로감 케어|\\n주의사항: * 영·유아, 어린이, 임산부 및 수유부는 섭취에 주의|* 과다 섭취 시 일시적으로 피부가 황색으로 변할 수 있음|'),\n",
       " Document(metadata={'제품명': '루테인 지아잔틴 플러스'}, page_content='제품명: 루테인 지아잔틴 플러스\\n영양성분: 비타민C,30|비타민E,3.3|아연,2.55|구리,240ug|루테인,18.182|지아잔틴,1.1818|\\n기능: 항산화|면역력 증진|시력 및 눈 피로감 케어|\\n주의사항: * 섭취 시 목에 걸릴 수 있으므로 반드시 물과 함께 섭취하십시오.|* 섭취 시 위장장애, 소화불량의 증상이 있을 경우 섭취를 중단하십시오.|* 개인의 신체 상태에 따라 이상 증상이 생길 경우 섭취를 중단하십시오.|* 섭취 전 제품에 이상이 있는 경우 섭취를 금하십시오.|* 특정 원료 성분에 알레르기 체질은 원료 성분을 확인 후 섭취하십시오.|* 영·유아, 어린이, 임산부 및 수유부는 섭취에 주의하십시오.|* 과다 섭취 시 일시적으로 피부가 황색으로 변할 수 있습니다.|'),\n",
       " Document(metadata={'제품명': '아이클리어 루테인아스타잔틴'}, page_content='제품명: 아이클리어 루테인아스타잔틴\\n영양성분: 비타민A,700ug|비타민C,30|비타민E,11|아연,8.5|루테인,20|아스타잔틴,6|\\n기능: 시력 및 눈 피로감 케어|항산화|면역력 증진|\\n주의사항: * 과다 섭취 시 일시적으로 피부가 황색으로 변할 수 있습니다.|* β-카로틴의 흡수를 저해할 수 있습니다.|* 임산부·수유부, 질병치료 중인 분은 섭취 전 의사와 상담 후 섭취 하십시오.|* 특정 성분에 알레르기가 있으신 분은 원료명을 확인 후 섭취하십시오.|* 개봉 또는 섭취 시 포장재에 의해 상처를 입을 수 있으니 주의하시기 바랍니다.|')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = kiwibm25_faiss_73_sup_product\n",
    "query = \"루테인 지아잔틴 아스타잔틴, 비타앤 히알루론산 피치맛\"\n",
    "docs = retriever.get_relevant_documents(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024.8</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024.10</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2024.8\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2024.10\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024.8</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024.10</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2024.8\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2024.10\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Connected to Predibase as </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">b5555c02</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-4e64-48dd-b993-2f03a91a605d</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">username</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">sehoonpark</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">@hanyang.ac.kr)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mConnected to Predibase as \u001b[0m\u001b[1;35mUser\u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;34m=\u001b[0m\u001b[93mb5555c02\u001b[0m\u001b[93m-4e64-48dd-b993-2f03a91a605d\u001b[0m\u001b[1;34m, \u001b[0m\u001b[1;33musername\u001b[0m\u001b[1;34m=\u001b[0m\u001b[1;35msehoonpark\u001b[0m\u001b[1;34m@hanyang.ac.kr\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "Question: \t 루테인 지아잔틴 아스타잔틴, 비타앤 히알루론산 피치맛 제품들을(를) 같이 먹고 있는데 적합하게 먹고 있어? 권장섭취량을 참고해서 지금 먹고 있는 영양제가 권장량에 작합한지 비교해줘\n",
      "Answer: \t 루테인 지아잔틴 아스타잔틴과 비타앤 히알루론산 피치맛 제품을 함께 섭취하는 것이 적합한지 확인하기 위해서는 각 제품의 영양성분과 권장 섭취량을 비교해야 합니다. \n",
      "\n",
      "1. **루테인 지아잔틴 아스타잔틴**:\n",
      "   - 비타민A: 210ug\n",
      "   - 아스타잔틴: 6mg\n",
      "   - 루테인지아잔틴복합추출물: 20mg\n",
      "\n",
      "2. **비타앤 히알루론산 피치맛**:\n",
      "   - 비타민C: 300mg\n",
      "   - 히알루론산: 120mg\n",
      "\n",
      "각 제품의 영양성분은 서로 중복되지 않으며, 특정 성분의 과다 섭취로 인한 부작용이 명시되어 있지 않습니다. 그러나, 비타민A와 비타민C의 경우 일반적인 권장 섭취량을 초과하지 않는지 확인해야 합니다. \n",
      "\n",
      "- **비타민A**: 성인 남성의 경우 하루 권장량은 약 900ug, 여성의 경우 약 700ug입니다. 루테인 지아잔틴 아스타잔틴의 비타민A 함량은 210ug로, 권장량을 초과하지 않습니다.\n",
      "- **비타민C**: 성인의 경우 하루 권장량은 약 75-90mg입니다. 비타앤 히알루론산 피치맛의 비타민C 함량은 300mg로, 권장량을 초과할 수 있으므로 주의가 필요합니다.\n",
      "\n",
      "따라서, 두 제품을 함께 섭취하는 것은 일반적으로 문제가 없으나, 비타민C의 경우 권장량을 초과할 수 있으므로 주의가 필요합니다. 개인의 건강 상태에 따라 다를 수 있으니, 의사나 영양사와 상담하는 것이 좋습니다.\n",
      "Relevance: \t grounded\n"
     ]
    }
   ],
   "source": [
    "def prompt_classification(llm, prompt):\n",
    "    if '추천' in prompt and '분석' not in prompt:\n",
    "        response = '제품 추천을 원하는 문장입니다.'\n",
    "    elif '분석' in prompt and '추천' not in prompt:\n",
    "        response = '문제 해결을 위한 분석을 원하는 문장입니다.'\n",
    "    else:\n",
    "        messages = [\n",
    "            SystemMessage(\n",
    "                content=\"You are an assistant designed to classify user requests into one of two categories: (1) product recommendation or (2) problem-solving analysis. Your goal is to accurately determine whether the user is asking for product suggestions or seeking analytical help to resolve a problem based on the content and intent of the user's query.\"\n",
    "            ),\n",
    "            HumanMessage(\n",
    "                content=f\"{prompt}라는 문장이 제품 추천을 원하는 문장인지 문제 해결을 위한 분석을 원하는 문장인지 아니면 둘 다 아닌지 답변해줘\"\n",
    "            )\n",
    "        ]\n",
    "    response = llm.invoke(messages).content\n",
    "    return response\n",
    "    \n",
    "def make_retrieveQA_form(contexts,question):\n",
    "    prompt = \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\" + contexts + \"Question:\" + question + \"Helpful Answer: \"\n",
    "    return prompt\n",
    "\n",
    "def solar_generate_text(client, prompt, adapter_id, max_new_tokens):\n",
    "    answer = client.generate(prompt, adapter_id=adapter_id, max_new_tokens=max_new_tokens).generated_text\n",
    "    return answer\n",
    "\n",
    "def qa_chain_generate_text(qa_chain, prompt):\n",
    "    if qa_chain =='solar_qa_chain':\n",
    "        answer = solar_generate_text(client, prompt, adapter_id, max_new_tokens)\n",
    "    else:\n",
    "        answer = qa_chain.invoke({\"query\": prompt})['result']\n",
    "    return answer\n",
    "\n",
    "def generate_chat(llm, prompt):\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are an helpful assistant.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=prompt\n",
    "        )\n",
    "    ]\n",
    "    response = llm.invoke(prompt).content\n",
    "    return response\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str  # Prompt\n",
    "    context: str  # Retrive result\n",
    "    answer: str  # Answer\n",
    "    relevance: str  # relevance check\n",
    "    prompt_type: str # Analysis / Recommend\n",
    "    product_type: str # Sup / Medication\n",
    "    \n",
    "def prompt_class(state : GraphState) -> GraphState:\n",
    "    p_type = prompt_classification(base_llm, prompt)\n",
    "    return GraphState(prompt_type = p_type)\n",
    "\n",
    "def product_type(state : GraphState) -> GraphState:\n",
    "    if tab == 'medi':\n",
    "        return GraphState(product_type = 'medi')\n",
    "\n",
    "def retrieve_medi_documents(question):\n",
    "    retrieved_docs = \"\"\n",
    "    info_retriever = kiwibm25_faiss_73_medi_info\n",
    "    retrieved_info_docs = info_retriever.invoke(question)\n",
    "    \n",
    "    product_retriever = kiwibm25_faiss_73_medi_product\n",
    "    retrieved_product_docs = product_retriever.invoke(retrieved_info_docs[0].page_content)\n",
    "    # 검색된 문서를 context 키에 저장합니다.\n",
    "    retrieved_info, medi_product = \"\", \"\"\n",
    "    for info in retrieved_info_docs:\n",
    "        retrieved_info += info.page_content + '\\n'\n",
    "    for m_product in retrieved_product_docs:\n",
    "        medi_product += m_product.page_content + '\\n'\n",
    "    retrieved_docs = retrieved_info + \"를 고려하여 제품을 추천하는데, \\n \" + medi_product + \"이 정보들을 참고해서 Question 에 대한 답을 해줘 Question : \" + question #### prompt\n",
    "    return retrieved_docs \n",
    "\n",
    "def web_retriever(unknown_list, llm):\n",
    "    retrieved_docs = []\n",
    "    targets = ''\n",
    "    for target in unknown_list:\n",
    "        targets += target + ', '\n",
    "        search_result = find_info_by_web_search(target+' 영양성분')\n",
    "        search_result = generate_chat(base_llm, search_result + '이 내용을 참고해서 제품 이름과 영양성분을 정리해줘 정보가 명확하지 않을 경우 찾지 못했다고 말해주고 정리한 정보를 웹 검색으로 가져왔기 때문에 정확하지는 않다고도 말해줘')\n",
    "        retrieved_docs.append(Document(page_content=search_result, metadata={\"제품명\": target}))\n",
    "    print(targets) ## Unknown List\n",
    "    return retrieved_docs, targets\n",
    "\n",
    "def retrieve_document(state: GraphState) -> GraphState:\n",
    "    if state['product_type'] == 'medi':\n",
    "        retrieved_docs = retrieve_medi_documents(state[\"question\"])\n",
    "    else:\n",
    "        retriever = kiwibm25_faiss_73_sup_product\n",
    "        retrieved_docs = retriever.invoke(state[\"question\"])\n",
    "        targets = ''\n",
    "        search_result_list = []\n",
    "        if len(unknown_list) != 0:\n",
    "            search_result_list, targets = web_retriever(unknown_list, base_llm)\n",
    "            \n",
    "    context_result = retrieved_docs + search_result_list\n",
    "    n_question = targets + state['question']\n",
    "    return GraphState(context = context_result, question = n_question) ###\n",
    "\n",
    "#Solar Chatbot model을 사용하여 답변을 생성합니다.\n",
    "def llm_answer(state: GraphState) -> GraphState:\n",
    "    if state['product_type'] == 'medi':\n",
    "        return GraphState(\n",
    "        answer = generate_chat(base_llm, state['context']),\n",
    "        context=state[\"context\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "    else:       \n",
    "        contexts = \", \".join([state['context'][i].page_content for i in range(len(state['context']))])\n",
    "        prompt = make_retrieveQA_form(contexts,state['question'])\n",
    "        return GraphState(\n",
    "            answer = qa_chain_generate_text(qa_chain, prompt),\n",
    "            context=state[\"context\"],\n",
    "            question=state[\"question\"],\n",
    "        )\n",
    "    \n",
    "# Upstage Ground Checker로 관련성 체크를 실행합니다.\n",
    "def relevance_check(state: GraphState) -> GraphState:\n",
    "    # 관련성 체크를 실행합니다. 결과: grounded, notGrounded, notSure\n",
    "    response = upstage_ground_checker.run(\n",
    "        {\"context\": state[\"context\"], \"answer\": state[\"answer\"]}\n",
    "    )\n",
    "    return GraphState(\n",
    "        relevance=response,\n",
    "        context=state[\"context\"],\n",
    "        answer=state[\"answer\"],\n",
    "        question=state[\"question\"],\n",
    "    )\n",
    "\n",
    "# 관련성 체크 결과를 반환합니다.\n",
    "def is_relevant(state: GraphState) -> GraphState:\n",
    "    if state[\"relevance\"] == \"grounded\":\n",
    "        return \"관련성 O\"\n",
    "    elif state[\"relevance\"] == \"notGrounded\":\n",
    "        return \"관련성 X\"\n",
    "    elif state[\"relevance\"] == \"notSure\":\n",
    "        return \"확인불가\"\n",
    "\n",
    "solar_llm = Predibase(model=\"solar-1-mini-chat-240612\", \n",
    "                predibase_api_key=os.environ[\"PREDIBASE_API_KEY\"], \n",
    "                adapter_id=\"AIMedicine\", \n",
    "                adapter_version=1,\n",
    "                max_new_tokens = 4096)\n",
    "\n",
    "gpt4o_llm = ChatOpenAI(model_name=\"gpt-4o\", temperature=0.3)\n",
    "solar_chat_llm = ChatUpstage(api_key=UPSTAGE_API_KEY, model=\"solar-1-mini-chat\")\n",
    "\n",
    "retriever = kiwibm25_faiss_73_sup_product\n",
    "\n",
    "# RetrievalQA Chain 설정\n",
    "gpt4o_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=gpt4o_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "solar_qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=solar_llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "#workflow.add_node(\"classification\", prompt_classification)\n",
    "workflow.add_node(\"product\", product_type)\n",
    "workflow.add_node(\"retrieve\", retrieve_document)  # 에이전트 노드를 추가합니다.\n",
    "workflow.add_node(\"llm_answer\", llm_answer)  # 정보 검색 노드를 추가합니다.\n",
    "workflow.add_node(\"relevance_check\", relevance_check)  # 답변의 문서에 대한 관련성 체크 노드를 추가합니다.\n",
    "\n",
    "#workflow.add_edge(\"classification\",\"retrieve\") # 프롬프트 타입 -> 검색\n",
    "workflow.add_edge(\"product\", \"retrieve\")\n",
    "workflow.add_edge(\"retrieve\", \"llm_answer\")  # 검색 -> 답변\n",
    "workflow.add_edge(\"llm_answer\", \"relevance_check\")  # 답변 -> 관련성 체크\n",
    "workflow.add_conditional_edges(\n",
    "    \"relevance_check\",  # 관련성 체크 노드에서 나온 결과를 is_relevant 함수에 전달합니다.\n",
    "    is_relevant,\n",
    "    {\n",
    "        \"관련성 O\": END,  # 관련성이 있으면 종료합니다.\n",
    "        \"관련성 X\": \"retrieve\",  # 관련성이 없으면 다시 답변을 생성합니다.\n",
    "        \"확인불가\": \"retrieve\",  # 관련성 체크 결과가 모호하다면 다시 답변을 생성합니다.\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.set_entry_point(\"product\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)\n",
    "\n",
    "# recursion_limit: 최대 반복 횟수, thread_id: 실행 ID (구분용)\n",
    "config = RunnableConfig(recursion_limit=5, configurable={\"thread_id\": \"SELF-RAG\"})\n",
    "\n",
    "#query = \"멀티비타민 올인원, 밀크씨슬\"\n",
    "#prompt = f\"저의 성별은 남성, 나이는 성인 (19세 이상)입니다. 제가 지금 먹고 있는 영양제 제품들은 {query} 이고 이렇게 먹으면 적절한지 권장 섭취량과 현재 복용중인 영양성분을 비교해서 확인해주세요.\"\n",
    "\n",
    "#prompt = \"두통이 있는데 어떤 약을 먹는게 좋을까?\"\n",
    "query = \"루테인 지아잔틴 아스타잔틴, 비타앤 히알루론산 피치맛\"\n",
    "prompt = f\"{query} 제품들을(를) 같이 먹고 있는데 적합하게 먹고 있어? 권장섭취량을 참고해서 지금 먹고 있는 영양제가 권장량에 작합한지 비교해줘\"\n",
    "pb_token = pb(api_token=PREDIBASE_API_KEY)\n",
    "client = pb_token.deployments.client(\"solar-1-mini-chat-240612\")\n",
    "adapter_id, max_new_tokens =\"AIMedicine/1\", 2000\n",
    "\n",
    "tab = 'sup' # sup or medi\n",
    "unknown_list = []\n",
    "inputs = GraphState(question=prompt, product_type=tab)\n",
    "#qa_chain = solar_qa_chain  # solar_qa_chain or gpt4o_qa_chain\n",
    "qa_chain = gpt4o_qa_chain\n",
    "base_llm = gpt4o_llm\n",
    "output = app.invoke(inputs, config=config)\n",
    "\n",
    "print(\"Question: \\t\", output[\"question\"])\n",
    "print(\"Answer: \\t\", output[\"answer\"])\n",
    "print(\"Relevance: \\t\", output[\"relevance\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
